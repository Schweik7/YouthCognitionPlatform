"""
ä¿®æ­£ç‰ˆç§‘å¤§è®¯é£è¯­éŸ³è¯„æµ‹XMLåˆ†æå™¨
åŸºäºå®é™…XMLæ•°æ®ç»“æ„é‡æ–°è®¾è®¡
"""

import xml.etree.ElementTree as ET
import json
import csv
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass
from enum import Enum
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class ErrorType(Enum):
    """é”™è¯¯ç±»å‹æšä¸¾"""

    CORRECT = 0  # æ­£ç¡®
    MISSED = 16  # æ¼è¯»
    ADDED = 32  # å¢è¯»
    REPEATED = 64  # å›è¯»
    REPLACED = 128  # æ›¿æ¢


class NodeType(Enum):
    """èŠ‚ç‚¹ç±»å‹æšä¸¾"""

    PAPER = "paper"  # è¯•å·å†…å®¹
    SIL = "sil"  # é™éŸ³
    FIL = "fil"  # å™ªéŸ³


@dataclass
class PhoneAnalysis:
    """éŸ³ç´ åˆ†æç»“æœ"""

    content: str = ""  # éŸ³ç´ å†…å®¹
    beg_pos: int = 0  # å¼€å§‹ä½ç½®ï¼ˆå¸§ï¼‰
    end_pos: int = 0  # ç»“æŸä½ç½®ï¼ˆå¸§ï¼‰
    time_len: int = 0  # æ—¶é•¿ï¼ˆå¸§ï¼‰
    dp_message: int = 0  # å¢æ¼ä¿¡æ¯
    perr_msg: int = 0  # é”™è¯¯ä¿¡æ¯
    perr_level_msg: int = 0  # ç½®ä¿¡åº¦ï¼ˆ1æœ€å¥½ï¼Œ3æœ€å·®ï¼‰
    is_yun: int = 0  # 0:å£°æ¯, 1:éŸµæ¯
    rec_node_type: str = ""  # èŠ‚ç‚¹ç±»å‹
    mono_tone: Optional[str] = None  # è°ƒå‹

    @property
    def duration_ms(self) -> int:
        """æŒç»­æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰"""
        return self.time_len * 10

    @property
    def error_type(self) -> ErrorType:
        """é”™è¯¯ç±»å‹"""
        return ErrorType(self.dp_message)

    @property
    def is_correct(self) -> bool:
        """æ˜¯å¦æ­£ç¡®"""
        return (
            self.dp_message == 0
            and self.perr_msg == 0
            and self.rec_node_type == "paper"
        )

    @property
    def confidence_level(self) -> str:
        """ç½®ä¿¡åº¦ç­‰çº§"""
        if self.perr_level_msg == 1:
            return "é«˜"
        elif self.perr_level_msg == 2:
            return "ä¸­"
        elif self.perr_level_msg == 3:
            return "ä½"
        else:
            return "æœªçŸ¥"

    @property
    def error_description(self) -> str:
        """é”™è¯¯æè¿°"""
        if self.is_correct:
            return "æ­£ç¡®"

        descriptions = []

        # å¢æ¼ä¿¡æ¯
        if self.dp_message == 16:
            descriptions.append("æ¼è¯»")
        elif self.dp_message == 32:
            descriptions.append("å¢è¯»")
        elif self.dp_message == 64:
            descriptions.append("å›è¯»")
        elif self.dp_message == 128:
            descriptions.append("æ›¿æ¢")

        # éŸ³ç´ é”™è¯¯ä¿¡æ¯
        if self.is_yun == 0:  # å£°æ¯
            if self.perr_msg == 1:
                descriptions.append("å£°æ¯é”™è¯¯")
        else:  # éŸµæ¯
            if self.perr_msg == 1:
                descriptions.append("éŸµæ¯é”™è¯¯")
            elif self.perr_msg == 2:
                descriptions.append("è°ƒå‹é”™è¯¯")
            elif self.perr_msg == 3:
                descriptions.append("éŸµæ¯å’Œè°ƒå‹é”™è¯¯")

        return "; ".join(descriptions) if descriptions else "æœªçŸ¥é”™è¯¯"


@dataclass
class SyllableAnalysis:
    """éŸ³èŠ‚åˆ†æç»“æœ"""

    content: str = ""  # éŸ³èŠ‚å†…å®¹
    symbol: str = ""  # æ‹¼éŸ³ï¼ˆå¸¦å£°è°ƒï¼‰
    beg_pos: int = 0  # å¼€å§‹ä½ç½®ï¼ˆå¸§ï¼‰
    end_pos: int = 0  # ç»“æŸä½ç½®ï¼ˆå¸§ï¼‰
    time_len: int = 0  # æ—¶é•¿ï¼ˆå¸§ï¼‰
    dp_message: int = 0  # å¢æ¼ä¿¡æ¯
    rec_node_type: str = ""  # èŠ‚ç‚¹ç±»å‹
    phones: List[PhoneAnalysis] = None

    def __post_init__(self):
        if self.phones is None:
            self.phones = []

    @property
    def duration_ms(self) -> int:
        """æŒç»­æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰"""
        return self.time_len * 10

    @property
    def error_type(self) -> ErrorType:
        """é”™è¯¯ç±»å‹"""
        return ErrorType(self.dp_message)

    @property
    def is_paper_content(self) -> bool:
        """æ˜¯å¦ä¸ºè¯•å·å†…å®¹"""
        return self.rec_node_type == "paper"

    @property
    def is_correct(self) -> bool:
        """éŸ³èŠ‚æ˜¯å¦æ­£ç¡®"""
        if not self.is_paper_content:
            return True  # éè¯•å·å†…å®¹ï¼ˆå¦‚é™éŸ³ï¼‰ä¸ç®—é”™è¯¯

        return self.dp_message == 0 and all(
            phone.is_correct for phone in self.phones if phone.rec_node_type == "paper"
        )

    @property
    def pinyin_without_tone(self) -> str:
        """ä¸å¸¦å£°è°ƒçš„æ‹¼éŸ³"""
        if not self.symbol:
            return ""
        # ç§»é™¤æ•°å­—å£°è°ƒ
        return "".join(char for char in self.symbol if not char.isdigit())

    @property
    def tone(self) -> Optional[int]:
        """å£°è°ƒ"""
        if not self.symbol:
            return None
        # æå–æœ€åçš„æ•°å­—
        for char in reversed(self.symbol):
            if char.isdigit():
                tone = int(char)
                return 0 if tone == 5 else tone  # 5è¡¨ç¤ºè½»å£°ï¼Œè½¬æ¢ä¸º0
        return None

    @property
    def error_summary(self) -> str:
        """é”™è¯¯æ‘˜è¦"""
        if self.is_correct:
            return "æ­£ç¡®"

        errors = []

        # éŸ³èŠ‚çº§é”™è¯¯
        if self.dp_message != 0:
            errors.append(f"éŸ³èŠ‚{self.error_type.name}")

        # éŸ³ç´ çº§é”™è¯¯
        for phone in self.phones:
            if phone.rec_node_type == "paper" and not phone.is_correct:
                errors.append(f"{phone.content}({phone.error_description})")

        return "; ".join(errors) if errors else "æœªçŸ¥é”™è¯¯"


@dataclass
class CharacterAnalysis:
    """å•å­—åˆ†æç»“æœ"""

    character: str = ""  # æ±‰å­—
    expected_pinyin: str = ""  # æœŸæœ›æ‹¼éŸ³
    beg_pos: int = 0  # å¼€å§‹ä½ç½®ï¼ˆå¸§ï¼‰
    end_pos: int = 0  # ç»“æŸä½ç½®ï¼ˆå¸§ï¼‰
    time_len: int = 0  # æ€»æ—¶é•¿ï¼ˆå¸§ï¼‰
    syllables: List[SyllableAnalysis] = None  # æ‰€æœ‰éŸ³èŠ‚ï¼ˆåŒ…æ‹¬sil/fil/paperï¼‰

    def __post_init__(self):
        if self.syllables is None:
            self.syllables = []

    @property
    def duration_ms(self) -> int:
        """æŒç»­æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰"""
        return self.time_len * 10

    @property
    def paper_syllables(self) -> List[SyllableAnalysis]:
        """åªè¿”å›è¯•å·å†…å®¹çš„éŸ³èŠ‚"""
        return [syll for syll in self.syllables if syll.is_paper_content]

    @property
    def sil_syllables(self) -> List[SyllableAnalysis]:
        """é™éŸ³éŸ³èŠ‚"""
        return [syll for syll in self.syllables if syll.rec_node_type == "sil"]

    @property
    def fil_syllables(self) -> List[SyllableAnalysis]:
        """å™ªéŸ³éŸ³èŠ‚"""
        return [syll for syll in self.syllables if syll.rec_node_type == "fil"]

    @property
    def is_read(self) -> bool:
        """æ˜¯å¦è¢«æœ—è¯»ï¼ˆæœ‰paperå†…å®¹ï¼‰"""
        return len(self.paper_syllables) > 0

    @property
    def is_correct(self) -> bool:
        """æ˜¯å¦æ­£ç¡®"""
        if not self.is_read:
            return False  # æ²¡æœ‰æœ—è¯»å°±æ˜¯é”™è¯¯

        # åªæ£€æŸ¥è¯•å·å†…å®¹çš„éŸ³èŠ‚
        return all(syll.is_correct for syll in self.paper_syllables)

    @property
    def actual_pinyin(self) -> str:
        """å®é™…è¯»å‡ºçš„æ‹¼éŸ³"""
        paper_sylls = self.paper_syllables
        if paper_sylls:
            return paper_sylls[0].symbol  # é€šå¸¸ä¸€ä¸ªå­—åªæœ‰ä¸€ä¸ªè¯•å·éŸ³èŠ‚
        return ""

    @property
    def total_silence_duration(self) -> int:
        """æ€»é™éŸ³æ—¶é•¿ï¼ˆæ¯«ç§’ï¼‰"""
        return sum(syll.duration_ms for syll in self.sil_syllables)

    @property
    def actual_speech_duration(self) -> int:
        """å®é™…è¯­éŸ³æ—¶é•¿ï¼ˆæ¯«ç§’ï¼‰"""
        return sum(syll.duration_ms for syll in self.paper_syllables)

    @property
    def status_summary(self) -> str:
        """çŠ¶æ€æ‘˜è¦"""
        if not self.is_read:
            return "æ¼è¯»"
        elif self.is_correct:
            return "æ­£ç¡®"
        else:
            paper_sylls = self.paper_syllables
            if paper_sylls:
                return paper_sylls[0].error_summary
            return "æœªçŸ¥é”™è¯¯"


@dataclass
class EvaluationAnalysis:
    """å®Œæ•´çš„è¯„æµ‹åˆ†æç»“æœ"""

    # åŸºæœ¬ä¿¡æ¯
    xml_file: str = ""
    analysis_time: datetime = None

    # æ•´ä½“åˆ†æ•°
    overall_score: float = 0.0
    phone_score: float = 0.0
    tone_score: float = 0.0
    fluency_score: float = 0.0
    integrity_score: float = 0.0

    # çŠ¶æ€ä¿¡æ¯
    is_rejected: bool = False
    except_info: Optional[str] = None
    total_time: int = 0  # æ€»æ—¶é•¿ï¼ˆå¸§ï¼‰

    # è¯¦ç»†åˆ†æ
    characters: List[CharacterAnalysis] = None

    # åŸå§‹æ•°æ®
    raw_xml: str = ""

    def __post_init__(self):
        if self.analysis_time is None:
            self.analysis_time = datetime.now()
        if self.characters is None:
            self.characters = []

    @property
    def total_duration_ms(self) -> int:
        """æ€»æ—¶é•¿ï¼ˆæ¯«ç§’ï¼‰"""
        return self.total_time * 10

    @property
    def total_characters(self) -> int:
        """æ€»å­—æ•°"""
        return len(self.characters)

    @property
    def read_characters(self) -> int:
        """å·²æœ—è¯»å­—æ•°"""
        return len([char for char in self.characters if char.is_read])

    @property
    def correct_characters(self) -> int:
        """æ­£ç¡®å­—æ•°"""
        return len([char for char in self.characters if char.is_correct])

    @property
    def missed_characters(self) -> int:
        """æ¼è¯»å­—æ•°"""
        return len([char for char in self.characters if not char.is_read])

    @property
    def character_accuracy_rate(self) -> float:
        """å­—å‡†ç¡®ç‡"""
        if self.total_characters == 0:
            return 0.0
        return self.correct_characters / self.total_characters * 100

    @property
    def reading_completion_rate(self) -> float:
        """æœ—è¯»å®Œæˆç‡"""
        if self.total_characters == 0:
            return 0.0
        return self.read_characters / self.total_characters * 100


class XfyunXMLAnalyzer:
    """ç§‘å¤§è®¯é£XMLåˆ†æå™¨ - åŸºäºå®é™…æ•°æ®ç»“æ„"""

    @staticmethod
    def analyze_xml_file(xml_file_path: Path) -> EvaluationAnalysis:
        """åˆ†æXMLæ–‡ä»¶"""
        try:
            with open(xml_file_path, "r", encoding="utf-8") as f:
                xml_content = f.read()

            result = XfyunXMLAnalyzer.analyze_xml_content(xml_content)
            result.xml_file = str(xml_file_path)
            return result

        except Exception as e:
            logger.error(f"åˆ†æXMLæ–‡ä»¶å¤±è´¥: {e}")
            raise

    @staticmethod
    def analyze_xml_content(xml_content: str) -> EvaluationAnalysis:
        """åˆ†æXMLå†…å®¹"""
        result = EvaluationAnalysis()
        result.raw_xml = xml_content

        try:
            root = ET.fromstring(xml_content)

            # æŸ¥æ‰¾è¯„æµ‹ç»“æœèŠ‚ç‚¹
            read_syllable = root.find(".//read_syllable")

            if read_syllable is not None:
                # è§£ææ•´ä½“åˆ†æ•°
                result.overall_score = float(read_syllable.get("total_score", 0))
                result.phone_score = float(read_syllable.get("phone_score", 0))
                result.tone_score = float(read_syllable.get("tone_score", 0))
                result.fluency_score = float(read_syllable.get("fluency_score", 0))
                result.integrity_score = float(read_syllable.get("integrity_score", 0))

                # è§£æçŠ¶æ€ä¿¡æ¯
                result.except_info = read_syllable.get("except_info")
                result.total_time = int(read_syllable.get("time_len", 0))

                # è§£æå­—ç¬¦è¯¦æƒ…
                result.characters = XfyunXMLAnalyzer._parse_characters(read_syllable)

            logger.info(f"XMLè§£æå®Œæˆï¼Œæ€»åˆ†: {result.overall_score}")

        except ET.ParseError as e:
            logger.error(f"XMLè§£æå¤±è´¥: {e}")
            raise
        except Exception as e:
            logger.error(f"ç»“æœè§£æè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            raise

        return result

    @staticmethod
    def _parse_characters(read_syllable_node) -> List[CharacterAnalysis]:
        """è§£æå­—ç¬¦èŠ‚ç‚¹"""
        characters = []

        # æ¯ä¸ªsentenceå¯¹åº”ä¸€ä¸ªå­—
        for sentence_node in read_syllable_node.findall(".//sentence"):
            char_content = sentence_node.get("content", "")
            if not char_content:
                continue

            character = CharacterAnalysis(
                character=char_content,
                beg_pos=int(sentence_node.get("beg_pos", 0)),
                end_pos=int(sentence_node.get("end_pos", 0)),
                time_len=int(sentence_node.get("time_len", 0)),
            )

            # è·å–wordèŠ‚ç‚¹ä¸­çš„æœŸæœ›æ‹¼éŸ³
            word_node = sentence_node.find(".//word")
            if word_node is not None:
                character.expected_pinyin = word_node.get("symbol", "")

                # è§£ææ‰€æœ‰éŸ³èŠ‚ï¼ˆåŒ…æ‹¬sil/fil/paperï¼‰
                character.syllables = XfyunXMLAnalyzer._parse_syllables_in_word(
                    word_node
                )

            characters.append(character)

        return characters

    @staticmethod
    def _parse_syllables_in_word(word_node) -> List[SyllableAnalysis]:
        """è§£æwordä¸­çš„æ‰€æœ‰éŸ³èŠ‚"""
        syllables = []

        for syll_node in word_node.findall(".//syll"):
            syllable = SyllableAnalysis(
                content=syll_node.get("content", ""),
                symbol=syll_node.get("symbol", ""),
                beg_pos=int(syll_node.get("beg_pos", 0)),
                end_pos=int(syll_node.get("end_pos", 0)),
                time_len=int(syll_node.get("time_len", 0)),
                dp_message=int(syll_node.get("dp_message", 0)),
                rec_node_type=syll_node.get("rec_node_type", ""),
            )

            # è§£æéŸ³ç´ 
            syllable.phones = XfyunXMLAnalyzer._parse_phones_in_syllable(syll_node)
            syllables.append(syllable)

        return syllables

    @staticmethod
    def _parse_phones_in_syllable(syll_node) -> List[PhoneAnalysis]:
        """è§£æéŸ³èŠ‚ä¸­çš„éŸ³ç´ """
        phones = []

        for phone_node in syll_node.findall(".//phone"):
            phone = PhoneAnalysis(
                content=phone_node.get("content", ""),
                beg_pos=int(phone_node.get("beg_pos", 0))
                if phone_node.get("beg_pos")
                else 0,
                end_pos=int(phone_node.get("end_pos", 0))
                if phone_node.get("end_pos")
                else 0,
                time_len=int(phone_node.get("time_len", 0))
                if phone_node.get("time_len")
                else 0,
                dp_message=int(phone_node.get("dp_message", 0)),
                perr_msg=int(phone_node.get("perr_msg", 0)),
                perr_level_msg=int(phone_node.get("perr_level_msg", 0)),
                is_yun=int(phone_node.get("is_yun", 0)),
                rec_node_type=phone_node.get("rec_node_type", ""),
                mono_tone=phone_node.get("mono_tone"),
            )
            phones.append(phone)

        return phones


class AnalysisReporter:
    """åˆ†ææŠ¥å‘Šç”Ÿæˆå™¨"""

    @staticmethod
    def print_detailed_analysis(analysis: EvaluationAnalysis):
        """æ‰“å°è¯¦ç»†åˆ†æç»“æœ"""
        print("\n" + "=" * 80)
        print("ğŸ™ï¸  ç§‘å¤§è®¯é£è¯­éŸ³è¯„æµ‹è¯¦ç»†åˆ†æ")
        print("=" * 80)

        # åŸºæœ¬ä¿¡æ¯
        print(f"ğŸ“ XMLæ–‡ä»¶: {analysis.xml_file}")
        print(f"ğŸ• åˆ†ææ—¶é—´: {analysis.analysis_time.strftime('%Y-%m-%d %H:%M:%S')}")
        print(
            f"â±ï¸  æ€»æ—¶é•¿: {analysis.total_duration_ms}ms ({analysis.total_duration_ms / 1000:.1f}ç§’)"
        )

        # æ•´ä½“åˆ†æ•°
        print(f"\nğŸ“Š æ•´ä½“è¯„åˆ†")
        print("-" * 50)
        print(
            f"æ€»åˆ†: {analysis.overall_score:6.2f} | å£°éŸµåˆ†: {analysis.phone_score:6.2f}"
        )
        print(
            f"è°ƒå‹åˆ†: {analysis.tone_score:6.2f} | æµç•…åº¦: {analysis.fluency_score:6.2f}"
        )
        print(f"å®Œæ•´åº¦: {analysis.integrity_score:6.2f}")

        # ç»Ÿè®¡ä¿¡æ¯
        print(f"\nğŸ“ˆ ç»Ÿè®¡ä¿¡æ¯")
        print("-" * 50)
        print(
            f"æ€»å­—æ•°: {analysis.total_characters:3d} | å·²è¯»å­—æ•°: {analysis.read_characters:3d} | æ­£ç¡®å­—æ•°: {analysis.correct_characters:3d}"
        )
        print(
            f"æ¼è¯»å­—æ•°: {analysis.missed_characters:3d} | å­—å‡†ç¡®ç‡: {analysis.character_accuracy_rate:5.1f}% | å®Œæˆç‡: {analysis.reading_completion_rate:5.1f}%"
        )

        # è¯¦ç»†å­—ç¬¦åˆ†æ
        print(f"\nğŸ” é€å­—è¯¦ç»†åˆ†æ")
        print("-" * 80)

        for i, char in enumerate(analysis.characters, 1):
            # å­—ç¬¦åŸºæœ¬ä¿¡æ¯
            status_icon = "âœ…" if char.is_correct else ("â­•" if char.is_read else "âŒ")
            print(
                f"\n{i:2d}. å­—ç¬¦: {char.character:2s} [{char.expected_pinyin:8s}] {status_icon} {char.status_summary}"
            )
            print(
                f"    æ€»æ—¶é•¿: {char.duration_ms:4d}ms | è¯­éŸ³: {char.actual_speech_duration:3d}ms | é™éŸ³: {char.total_silence_duration:3d}ms"
            )

            if char.actual_pinyin and char.actual_pinyin != char.expected_pinyin:
                print(f"    å®é™…è¯»éŸ³: {char.actual_pinyin}")

            # éŸ³èŠ‚è¯¦æƒ…
            if char.syllables:
                print(f"    éŸ³èŠ‚è¯¦æƒ…:")
                for j, syll in enumerate(char.syllables):
                    syll_type = {"paper": "ğŸ“", "sil": "ğŸ”‡", "fil": "ğŸ”Š"}.get(
                        syll.rec_node_type, "â“"
                    )
                    if syll.rec_node_type == "paper":
                        syll_status = "âœ…" if syll.is_correct else "âŒ"
                        print(
                            f"      {j + 1}. {syll_type} {syll.content:4s} [{syll.symbol:6s}] {syll_status} {syll.duration_ms:3d}ms"
                        )
                        if not syll.is_correct:
                            print(f"         é”™è¯¯: {syll.error_summary}")

                        # éŸ³ç´ è¯¦æƒ…
                        phone_line = "         éŸ³ç´ : "
                        for phone in syll.phones:
                            if phone.rec_node_type == "paper":
                                phone_status = "âœ…" if phone.is_correct else "âŒ"
                                phone_type = "éŸµ" if phone.is_yun else "å£°"
                                phone_line += (
                                    f"{phone.content}({phone_type}){phone_status} "
                                )
                        if phone_line.strip().endswith("éŸ³ç´ :"):
                            phone_line += "æ— "
                        print(phone_line)
                    else:
                        print(
                            f"      {j + 1}. {syll_type} {syll.rec_node_type:4s} {syll.duration_ms:3d}ms"
                        )

        # é”™è¯¯ç»Ÿè®¡
        error_stats = AnalysisReporter._calculate_error_statistics(analysis)
        if error_stats:
            print(f"\nğŸ“‰ é”™è¯¯ç»Ÿè®¡")
            print("-" * 50)
            for error_type, count in error_stats.items():
                print(f"{error_type}: {count}æ¬¡")

        # æ—¶é—´åˆ†æ
        print(f"\nâ±ï¸  æ—¶é—´åˆ†æ")
        print("-" * 50)
        if analysis.characters:
            read_chars = [c for c in analysis.characters if c.is_read]
            if read_chars:
                avg_char_time = sum(c.actual_speech_duration for c in read_chars) / len(
                    read_chars
                )
                avg_total_time = sum(c.duration_ms for c in analysis.characters) / len(
                    analysis.characters
                )
                total_speech_time = sum(
                    c.actual_speech_duration for c in analysis.characters
                )
                total_silence_time = sum(
                    c.total_silence_duration for c in analysis.characters
                )

                print(f"å¹³å‡å­—è¯­éŸ³æ—¶é•¿: {avg_char_time:.0f}ms")
                print(f"å¹³å‡å­—æ€»æ—¶é•¿: {avg_total_time:.0f}ms")
                print(
                    f"æ€»è¯­éŸ³æ—¶é•¿: {total_speech_time}ms ({total_speech_time / 1000:.1f}ç§’)"
                )
                print(
                    f"æ€»é™éŸ³æ—¶é•¿: {total_silence_time}ms ({total_silence_time / 1000:.1f}ç§’)"
                )

                if analysis.total_duration_ms > 0:
                    speech_ratio = total_speech_time / analysis.total_duration_ms * 100
                    print(f"è¯­éŸ³å æ¯”: {speech_ratio:.1f}%")

    @staticmethod
    def _calculate_error_statistics(analysis: EvaluationAnalysis) -> Dict[str, int]:
        """è®¡ç®—é”™è¯¯ç»Ÿè®¡"""
        error_stats = {}

        for char in analysis.characters:
            if not char.is_read:
                error_stats["æ¼è¯»"] = error_stats.get("æ¼è¯»", 0) + 1
            elif not char.is_correct:
                for syll in char.paper_syllables:
                    if not syll.is_correct:
                        for phone in syll.phones:
                            if phone.rec_node_type == "paper" and not phone.is_correct:
                                error_desc = phone.error_description
                                error_stats[error_desc] = (
                                    error_stats.get(error_desc, 0) + 1
                                )

        return dict(sorted(error_stats.items(), key=lambda x: x[1], reverse=True))

    @staticmethod
    def export_to_csv(analysis: EvaluationAnalysis, output_path: Path) -> bool:
        """å¯¼å‡ºåˆ°CSV"""
        try:
            output_path.parent.mkdir(parents=True, exist_ok=True)

            with open(output_path, "w", newline="", encoding="utf-8-sig") as f:
                writer = csv.writer(f)

                # å†™å…¥è¡¨å¤´
                headers = [
                    "åºå·",
                    "æ±‰å­—",
                    "æœŸæœ›æ‹¼éŸ³",
                    "å®é™…æ‹¼éŸ³",
                    "çŠ¶æ€",
                    "æ˜¯å¦æ­£ç¡®",
                    "æ€»æ—¶é•¿(ms)",
                    "è¯­éŸ³æ—¶é•¿(ms)",
                    "é™éŸ³æ—¶é•¿(ms)",
                    "é”™è¯¯æè¿°",
                    "å¼€å§‹ä½ç½®(å¸§)",
                    "ç»“æŸä½ç½®(å¸§)",
                ]
                writer.writerow(headers)

                # å†™å…¥æ•°æ®
                for i, char in enumerate(analysis.characters, 1):
                    row = [
                        i,
                        char.character,
                        char.expected_pinyin,
                        char.actual_pinyin,
                        "å·²è¯»" if char.is_read else "æ¼è¯»",
                        "æ­£ç¡®" if char.is_correct else "é”™è¯¯",
                        char.duration_ms,
                        char.actual_speech_duration,
                        char.total_silence_duration,
                        char.status_summary,
                        char.beg_pos,
                        char.end_pos,
                    ]
                    writer.writerow(row)

            logger.info(f"CSVå·²å¯¼å‡º: {output_path}")
            return True

        except Exception as e:
            logger.error(f"å¯¼å‡ºCSVå¤±è´¥: {e}")
            return False

    @staticmethod
    def generate_summary_report(
        analysis: EvaluationAnalysis, output_path: Path
    ) -> bool:
        """ç”Ÿæˆæ‘˜è¦æŠ¥å‘Š"""
        try:
            output_path.parent.mkdir(parents=True, exist_ok=True)

            with open(output_path, "w", encoding="utf-8") as f:
                f.write("ç§‘å¤§è®¯é£è¯­éŸ³è¯„æµ‹åˆ†ææŠ¥å‘Š\n")
                f.write("=" * 60 + "\n\n")

                # åŸºæœ¬ä¿¡æ¯
                f.write("ğŸ“‹ åŸºæœ¬ä¿¡æ¯\n")
                f.write("-" * 30 + "\n")
                f.write(f"XMLæ–‡ä»¶: {analysis.xml_file}\n")
                f.write(
                    f"åˆ†ææ—¶é—´: {analysis.analysis_time.strftime('%Y-%m-%d %H:%M:%S')}\n"
                )
                f.write(
                    f"æ€»æ—¶é•¿: {analysis.total_duration_ms}ms ({analysis.total_duration_ms / 1000:.1f}ç§’)\n\n"
                )

                # æ•´ä½“è¯„åˆ†
                f.write("ğŸ“Š æ•´ä½“è¯„åˆ†\n")
                f.write("-" * 30 + "\n")
                f.write(f"æ€»åˆ†: {analysis.overall_score:.2f}\n")
                f.write(f"å£°éŸµåˆ†: {analysis.phone_score:.2f}\n")
                f.write(f"è°ƒå‹åˆ†: {analysis.tone_score:.2f}\n")
                f.write(f"æµç•…åº¦åˆ†: {analysis.fluency_score:.2f}\n")
                f.write(f"å®Œæ•´åº¦åˆ†: {analysis.integrity_score:.2f}\n\n")

                # ç»Ÿè®¡æ‘˜è¦
                f.write("ğŸ“ˆ ç»Ÿè®¡æ‘˜è¦\n")
                f.write("-" * 30 + "\n")
                f.write(f"æ€»å­—æ•°: {analysis.total_characters}\n")
                f.write(f"å·²è¯»å­—æ•°: {analysis.read_characters}\n")
                f.write(f"æ­£ç¡®å­—æ•°: {analysis.correct_characters}\n")
                f.write(f"æ¼è¯»å­—æ•°: {analysis.missed_characters}\n")
                f.write(f"å­—å‡†ç¡®ç‡: {analysis.character_accuracy_rate:.1f}%\n")
                f.write(f"æœ—è¯»å®Œæˆç‡: {analysis.reading_completion_rate:.1f}%\n\n")

                # é”™è¯¯åˆ†æ
                error_stats = AnalysisReporter._calculate_error_statistics(analysis)
                if error_stats:
                    f.write("âŒ é”™è¯¯åˆ†æ\n")
                    f.write("-" * 30 + "\n")
                    for error_type, count in error_stats.items():
                        f.write(f"{error_type}: {count}æ¬¡\n")
                    f.write("\n")

                # è¯¦ç»†ç»“æœ
                f.write("ğŸ” è¯¦ç»†ç»“æœ\n")
                f.write("-" * 30 + "\n")
                for i, char in enumerate(analysis.characters, 1):
                    status = (
                        "âœ…æ­£ç¡®"
                        if char.is_correct
                        else ("â­•å·²è¯»" if char.is_read else "âŒæ¼è¯»")
                    )
                    f.write(
                        f"{i:2d}. {char.character} [{char.expected_pinyin}] {status}\n"
                    )
                    if (
                        char.actual_pinyin != char.expected_pinyin
                        and char.actual_pinyin
                    ):
                        f.write(f"    å®é™…è¯»éŸ³: {char.actual_pinyin}\n")
                    f.write(
                        f"    æ—¶é•¿: {char.duration_ms}ms (è¯­éŸ³:{char.actual_speech_duration}ms)\n"
                    )
                    if not char.is_correct and char.is_read:
                        f.write(f"    é”™è¯¯: {char.status_summary}\n")

            logger.info(f"æ‘˜è¦æŠ¥å‘Šå·²ç”Ÿæˆ: {output_path}")
            return True

        except Exception as e:
            logger.error(f"ç”Ÿæˆæ‘˜è¦æŠ¥å‘Šå¤±è´¥: {e}")
            return False


def analyze_xml_file_demo(xml_file_path: str):
    """æ¼”ç¤ºåˆ†æXMLæ–‡ä»¶"""
    xml_path = Path(xml_file_path)

    if not xml_path.exists():
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {xml_path}")
        return

    print(f"ğŸ” å¼€å§‹åˆ†æXMLæ–‡ä»¶: {xml_path.name}")

    try:
        # åˆ†æXML
        analyzer = XfyunXMLAnalyzer()
        analysis = analyzer.analyze_xml_file(xml_path)

        # æ˜¾ç¤ºè¯¦ç»†åˆ†æ
        AnalysisReporter.print_detailed_analysis(analysis)

        # ç”ŸæˆæŠ¥å‘Š
        output_dir = Path("./xml_analysis_results")
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        # CSVæŠ¥å‘Š
        csv_path = output_dir / f"analysis_{timestamp}.csv"
        AnalysisReporter.export_to_csv(analysis, csv_path)

        # æ‘˜è¦æŠ¥å‘Š
        summary_path = output_dir / f"summary_{timestamp}.txt"
        AnalysisReporter.generate_summary_report(analysis, summary_path)

        # JSONæ•°æ®
        json_path = output_dir / f"analysis_{timestamp}.json"
        export_analysis_to_json(analysis, json_path)

        print(f"\nğŸ“„ åˆ†ææŠ¥å‘Šå·²ç”Ÿæˆ:")
        print(f"   CSVè¯¦æƒ…: {csv_path}")
        print(f"   æ‘˜è¦æŠ¥å‘Š: {summary_path}")
        print(f"   JSONæ•°æ®: {json_path}")

    except Exception as e:
        print(f"âŒ åˆ†æå¤±è´¥: {e}")
        logger.exception("åˆ†æå¼‚å¸¸")


def export_analysis_to_json(analysis: EvaluationAnalysis, output_path: Path):
    """å¯¼å‡ºåˆ†æç»“æœä¸ºJSON"""
    try:
        output_path.parent.mkdir(parents=True, exist_ok=True)

        # æ„å»ºJSONæ•°æ®
        json_data = {
            "basic_info": {
                "xml_file": analysis.xml_file,
                "analysis_time": analysis.analysis_time.isoformat(),
                "total_duration_ms": analysis.total_duration_ms,
            },
            "scores": {
                "overall_score": analysis.overall_score,
                "phone_score": analysis.phone_score,
                "tone_score": analysis.tone_score,
                "fluency_score": analysis.fluency_score,
                "integrity_score": analysis.integrity_score,
            },
            "statistics": {
                "total_characters": analysis.total_characters,
                "read_characters": analysis.read_characters,
                "correct_characters": analysis.correct_characters,
                "missed_characters": analysis.missed_characters,
                "character_accuracy_rate": analysis.character_accuracy_rate,
                "reading_completion_rate": analysis.reading_completion_rate,
            },
            "characters": [],
        }

        # å­—ç¬¦è¯¦æƒ…
        for char in analysis.characters:
            char_data = {
                "character": char.character,
                "expected_pinyin": char.expected_pinyin,
                "actual_pinyin": char.actual_pinyin,
                "is_read": char.is_read,
                "is_correct": char.is_correct,
                "duration_ms": char.duration_ms,
                "speech_duration_ms": char.actual_speech_duration,
                "silence_duration_ms": char.total_silence_duration,
                "status": char.status_summary,
                "syllables": [],
            }

            # éŸ³èŠ‚è¯¦æƒ…
            for syll in char.syllables:
                syll_data = {
                    "content": syll.content,
                    "symbol": syll.symbol,
                    "type": syll.rec_node_type,
                    "duration_ms": syll.duration_ms,
                    "is_correct": syll.is_correct if syll.is_paper_content else None,
                    "error_summary": syll.error_summary
                    if syll.is_paper_content and not syll.is_correct
                    else None,
                }
                char_data["syllables"].append(syll_data)

            json_data["characters"].append(char_data)

        with open(output_path, "w", encoding="utf-8") as f:
            json.dump(json_data, f, ensure_ascii=False, indent=2)

        logger.info(f"JSONæ•°æ®å·²å¯¼å‡º: {output_path}")

    except Exception as e:
        logger.error(f"å¯¼å‡ºJSONå¤±è´¥: {e}")


def batch_analyze_xml_files(xml_dir_path: str):
    """æ‰¹é‡åˆ†æXMLæ–‡ä»¶"""
    xml_dir = Path(xml_dir_path)

    if not xml_dir.exists():
        print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {xml_dir}")
        return

    xml_files = list(xml_dir.glob("*.xml"))
    if not xml_files:
        print(f"âŒ åœ¨ç›®å½• {xml_dir} ä¸­æœªæ‰¾åˆ°XMLæ–‡ä»¶")
        return

    print(f"ğŸ” å¼€å§‹æ‰¹é‡åˆ†æ {len(xml_files)} ä¸ªXMLæ–‡ä»¶")

    analyzer = XfyunXMLAnalyzer()
    results = []

    for xml_file in xml_files:
        try:
            print(f"   æ­£åœ¨åˆ†æ: {xml_file.name}")
            analysis = analyzer.analyze_xml_file(xml_file)
            results.append(analysis)
        except Exception as e:
            print(f"   âŒ åˆ†æå¤±è´¥: {xml_file.name} - {e}")

    if results:
        # ç”Ÿæˆæ‰¹é‡æ‘˜è¦
        generate_batch_summary(results)
        print(f"\nâœ… æ‰¹é‡åˆ†æå®Œæˆï¼Œå…±æˆåŠŸåˆ†æ {len(results)} ä¸ªæ–‡ä»¶")
    else:
        print("âŒ æ²¡æœ‰æˆåŠŸåˆ†æä»»ä½•æ–‡ä»¶")


def generate_batch_summary(results: List[EvaluationAnalysis]):
    """ç”Ÿæˆæ‰¹é‡åˆ†ææ‘˜è¦"""
    output_dir = Path("./batch_xml_analysis")
    output_dir.mkdir(parents=True, exist_ok=True)

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    summary_path = output_dir / f"batch_summary_{timestamp}.txt"

    with open(summary_path, "w", encoding="utf-8") as f:
        f.write("æ‰¹é‡XMLåˆ†ææ‘˜è¦æŠ¥å‘Š\n")
        f.write("=" * 60 + "\n\n")

        f.write(f"åˆ†ææ–‡ä»¶æ•°: {len(results)}\n")
        f.write(f"åˆ†ææ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")

        if results:
            # æ•´ä½“ç»Ÿè®¡
            avg_overall = sum(r.overall_score for r in results) / len(results)
            avg_accuracy = sum(r.character_accuracy_rate for r in results) / len(
                results
            )
            avg_completion = sum(r.reading_completion_rate for r in results) / len(
                results
            )

            f.write("ğŸ“Š æ•´ä½“ç»Ÿè®¡\n")
            f.write("-" * 30 + "\n")
            f.write(f"å¹³å‡æ€»åˆ†: {avg_overall:.2f}\n")
            f.write(f"å¹³å‡å­—å‡†ç¡®ç‡: {avg_accuracy:.1f}%\n")
            f.write(f"å¹³å‡å®Œæˆç‡: {avg_completion:.1f}%\n\n")

            # åˆ†æ•°åˆ†å¸ƒ
            score_ranges = [
                (90, 100, "ä¼˜ç§€"),
                (80, 89, "è‰¯å¥½"),
                (70, 79, "ä¸­ç­‰"),
                (60, 69, "åŠæ ¼"),
                (0, 59, "ä¸åŠæ ¼"),
            ]

            f.write("ğŸ“ˆ åˆ†æ•°åˆ†å¸ƒ\n")
            f.write("-" * 30 + "\n")
            for min_score, max_score, level in score_ranges:
                count = len(
                    [r for r in results if min_score <= r.overall_score <= max_score]
                )
                percentage = count / len(results) * 100
                f.write(
                    f"{level}({min_score}-{max_score}): {count}ä¸ª ({percentage:.1f}%)\n"
                )
            f.write("\n")

            # è¯¦ç»†åˆ—è¡¨
            f.write("ğŸ“‹ è¯¦ç»†åˆ—è¡¨\n")
            f.write("-" * 30 + "\n")
            for i, result in enumerate(results, 1):
                f.write(f"{i:2d}. {Path(result.xml_file).stem}\n")
                f.write(
                    f"    æ€»åˆ†: {result.overall_score:5.1f} | å‡†ç¡®ç‡: {result.character_accuracy_rate:5.1f}% | å®Œæˆç‡: {result.reading_completion_rate:5.1f}%\n"
                )

    print(f"ğŸ“„ æ‰¹é‡æ‘˜è¦å·²ç”Ÿæˆ: {summary_path}")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ™ï¸  ç§‘å¤§è®¯é£XMLåˆ†æå·¥å…·")
    print("=" * 60)

    print("è¯·é€‰æ‹©æ“ä½œ:")
    print("1. åˆ†æå•ä¸ªXMLæ–‡ä»¶")
    print("2. æ‰¹é‡åˆ†æXMLæ–‡ä»¶")
    print("3. åˆ†æå½“å‰æä¾›çš„ç¤ºä¾‹XML")
    print("0. é€€å‡º")

    choice = input("\nè¯·é€‰æ‹© (0-3): ").strip()

    if choice == "1":
        xml_file = input("è¯·è¾“å…¥XMLæ–‡ä»¶è·¯å¾„: ").strip()
        analyze_xml_file_demo(xml_file)

    elif choice == "2":
        xml_dir = input("è¯·è¾“å…¥XMLæ–‡ä»¶ç›®å½•è·¯å¾„: ").strip()
        batch_analyze_xml_files(xml_dir)

    elif choice == "3":
        # åˆ†æå½“å‰æä¾›çš„ç¤ºä¾‹XML
        xml_file = r"ise-demo\ise_python3\results\evaluation_20250615_201641.xml"
        print("ğŸ” åˆ†æç¤ºä¾‹XMLæ–‡ä»¶" + xml_file)

        # åˆ›å»ºç¤ºä¾‹XMLæ–‡ä»¶ï¼ˆåŸºäºæ‚¨æä¾›çš„å†…å®¹ï¼‰
        sample_xml_path = Path(xml_file)
        if not sample_xml_path.exists():
            print("âŒ ç¤ºä¾‹XMLæ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·å…ˆå°†XMLå†…å®¹ä¿å­˜ä¸ºæ–‡ä»¶")
        else:
            analyze_xml_file_demo(str(sample_xml_path))

    elif choice == "0":
        print("ğŸ‘‹ å†è§!")

    else:
        print("âŒ æ— æ•ˆé€‰æ‹©")


if __name__ == "__main__":
    print("é€šç”¨XMLåˆ†æå·¥å…·")
    main()
